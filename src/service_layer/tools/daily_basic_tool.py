"""
è‚¡ç¥¨æ—¥æŒ‡æ ‡å·¥å…·
å°è£…Tushareçš„daily_basicæ–¹æ³•ï¼Œæä¾›æ¯æ—¥é‡è¦åŸºæœ¬é¢æŒ‡æ ‡æ•°æ®è·å–åŠŸèƒ½
ç”¨äºé€‰è‚¡åˆ†æã€æŠ¥è¡¨å±•ç¤ºç­‰
"""

import pandas as pd
import tushare as ts
from typing import Optional, Dict, Any
from langchain_core.tools import tool
from datetime import datetime, timedelta

from ..config.config_manager import config_manager


def _get_tushare_pro():
    """è·å–Tushare Pro APIå®ä¾‹"""
    try:
        tushare_token = config_manager.get_tushare_config()
        if not tushare_token:
            raise Exception("Tushare API tokenæœªé…ç½®")
        ts.set_token(tushare_token)
        pro = ts.pro_api()
        return pro
    except Exception as e:
        raise Exception(f"Tushare Pro APIåˆå§‹åŒ–å¤±è´¥: {str(e)}")


@tool
def get_daily_basic(
    ts_code: str = "",
    trade_date: str = "",
    start_date: str = "",
    end_date: str = "",
    fields: str = ""
) -> str:
    """
    è·å–è‚¡ç¥¨æ¯æ—¥é‡è¦åŸºæœ¬é¢æŒ‡æ ‡
    
    Args:
        ts_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚'000001.SZ'ï¼Œä¸ºç©ºåˆ™è·å–æ‰€æœ‰è‚¡ç¥¨
        trade_date: äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼YYYYMMDDï¼Œå¦‚'20180726'
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD  
        fields: æŒ‡å®šå­—æ®µï¼Œå¦‚'ts_code,trade_date,turnover_rate,volume_ratio,pe,pb'
        
    Returns:
        åŒ…å«æ—¥æŒ‡æ ‡æ•°æ®çš„JSONå­—ç¬¦ä¸²
        
    Examples:
        è·å–æŒ‡å®šæ—¥æœŸæ‰€æœ‰è‚¡ç¥¨åŸºæœ¬æŒ‡æ ‡: get_daily_basic('', '20180726')
        è·å–æŒ‡å®šè‚¡ç¥¨æ—¶é—´èŒƒå›´æ•°æ®: get_daily_basic('000001.SZ', '', '20180701', '20180731')
        è·å–æŒ‡å®šå­—æ®µ: get_daily_basic('000001.SZ', '20180726', '', '', 'ts_code,trade_date,turnover_rate,pe,pb')
    """
    try:
        print(f"ğŸ”„ å¼€å§‹è·å–æ—¥æŒ‡æ ‡æ•°æ® - è‚¡ç¥¨ä»£ç : {ts_code or 'å…¨éƒ¨'}, äº¤æ˜“æ—¥æœŸ: {trade_date or 'èŒƒå›´æŸ¥è¯¢'}")
        
        # å‚æ•°éªŒè¯ï¼šå¿…é¡»æä¾›äº¤æ˜“æ—¥æœŸæˆ–æ—¥æœŸèŒƒå›´
        if not trade_date and not (start_date and end_date):
            return f"âŒ é”™è¯¯: å¿…é¡»æä¾›trade_dateæˆ–start_date+end_dateå‚æ•°"
        
        # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼(å¦‚æœæä¾›)
        if ts_code and (len(ts_code) != 9 or '.' not in ts_code):
            return f"âŒ é”™è¯¯: è‚¡ç¥¨ä»£ç æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º'000001.SZ'æ ¼å¼ï¼Œå½“å‰è¾“å…¥: {ts_code}"
        
        # è·å–Tushare Proå®ä¾‹
        pro = _get_tushare_pro()
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        if ts_code:
            params['ts_code'] = ts_code
        if trade_date:
            params['trade_date'] = trade_date
        if start_date:
            params['start_date'] = start_date
        if end_date:
            params['end_date'] = end_date
        if fields:
            params['fields'] = fields
        else:
            # é»˜è®¤å¸¸ç”¨å­—æ®µ
            params['fields'] = 'ts_code,trade_date,close,turnover_rate,volume_ratio,pe,pb,ps,dv_ratio,dv_ttm,total_share,float_share,free_share,total_mv,circ_mv'
            
        print(f"ğŸ“… æŸ¥è¯¢å‚æ•°: {params}")
        print(f"ğŸ”Œ è°ƒç”¨Tushare daily_basicæ¥å£...")
        
        df = pro.daily_basic(**params)
        
        if df is None or df.empty:
            return f"âš ï¸ è­¦å‘Š: æœªè·å–åˆ°æ—¥æŒ‡æ ‡æ•°æ®ï¼Œå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–å‚æ•°é”™è¯¯"
        
        print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡æ—¥æŒ‡æ ‡æ•°æ®")
        
        # æ•°æ®é¢„å¤„ç†
        if 'trade_date' in df.columns and 'ts_code' in df.columns:
            df = df.sort_values(['trade_date', 'ts_code'], ascending=[True, True])
        
        # æ•°å€¼åˆ—å¤„ç†
        numeric_cols = ['close', 'turnover_rate', 'volume_ratio', 'pe', 'pb', 'ps', 
                       'dv_ratio', 'dv_ttm', 'total_share', 'float_share', 'free_share', 
                       'total_mv', 'circ_mv']
        
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ç»Ÿè®¡åˆ†æ
        stats = {
            "æ•°æ®æ¡æ•°": len(df),
            "æ¶‰åŠè‚¡ç¥¨æ•°": df['ts_code'].nunique() if 'ts_code' in df.columns else 0,
            "æ—¥æœŸèŒƒå›´": {
                "å¼€å§‹æ—¥æœŸ": df['trade_date'].min() if 'trade_date' in df.columns else None,
                "ç»“æŸæ—¥æœŸ": df['trade_date'].max() if 'trade_date' in df.columns else None
            } if 'trade_date' in df.columns else None,
        }
        
        # æ·»åŠ å…³é”®æŒ‡æ ‡ç»Ÿè®¡
        key_metrics_stats = {}
        for metric in ['pe', 'pb', 'turnover_rate', 'total_mv']:
            if metric in df.columns:
                metric_data = df[metric].dropna()
                if len(metric_data) > 0:
                    key_metrics_stats[metric] = {
                        "å¹³å‡å€¼": float(metric_data.mean()),
                        "ä¸­ä½æ•°": float(metric_data.median()),
                        "æœ€å°å€¼": float(metric_data.min()),
                        "æœ€å¤§å€¼": float(metric_data.max()),
                        "æ ‡å‡†å·®": float(metric_data.std())
                    }
        
        if key_metrics_stats:
            stats["å…³é”®æŒ‡æ ‡ç»Ÿè®¡"] = key_metrics_stats
        
        # æ ¼å¼åŒ–ç»“æœ
        result = {
            "query_params": {
                "ts_code": ts_code or "å…¨éƒ¨è‚¡ç¥¨",
                "trade_date": trade_date or f"{start_date}è‡³{end_date}",
                "fields": fields or "é»˜è®¤å­—æ®µ"
            },
            "statistics": stats,
            "columns": df.columns.tolist(),
            "sample_data": df.head(10).to_dict('records'),
        }
        
        # å¦‚æœæ˜¯å•ä¸ªè‚¡ç¥¨æŸ¥è¯¢ï¼Œæä¾›æ›´è¯¦ç»†çš„åˆ†æ
        if ts_code:
            stock_df = df[df['ts_code'] == ts_code] if 'ts_code' in df.columns else df
            if len(stock_df) > 0:
                latest_data = stock_df.iloc[-1]
                result["stock_analysis"] = {
                    "stock_code": ts_code,
                    "data_count": len(stock_df),
                    "latest_metrics": {
                        "äº¤æ˜“æ—¥æœŸ": latest_data.get('trade_date', 'N/A'),
                        "æ”¶ç›˜ä»·": float(latest_data.get('close', 0)) if pd.notna(latest_data.get('close')) else None,
                        "å¸‚ç›ˆç‡PE": float(latest_data.get('pe', 0)) if pd.notna(latest_data.get('pe')) else None,
                        "å¸‚å‡€ç‡PB": float(latest_data.get('pb', 0)) if pd.notna(latest_data.get('pb')) else None,
                        "æ¢æ‰‹ç‡": float(latest_data.get('turnover_rate', 0)) if pd.notna(latest_data.get('turnover_rate')) else None,
                        "æ€»å¸‚å€¼": float(latest_data.get('total_mv', 0)) if pd.notna(latest_data.get('total_mv')) else None
                    },
                    "recent_data": stock_df.tail(5).to_dict('records') if len(stock_df) > 0 else []
                }
        
        # å¦‚æœæ˜¯å•ä¸ªæ—¥æœŸæŸ¥è¯¢ï¼Œæä¾›å¸‚åœºæ¦‚è§ˆ
        if trade_date:
            # PEæ’åºåˆ†æ
            if 'pe' in df.columns:
                pe_data = df[df['pe'].notna() & (df['pe'] > 0)]
                if len(pe_data) > 0:
                    pe_sorted = pe_data.sort_values('pe')
                    result["market_overview"] = {
                        "trade_date": trade_date,
                        "total_stocks": len(df),
                        "valid_pe_stocks": len(pe_data),
                        "pe_analysis": {
                            "æœ€ä½PEè‚¡ç¥¨": pe_sorted.head(5)[['ts_code', 'pe', 'pb', 'total_mv']].to_dict('records'),
                            "æœ€é«˜PEè‚¡ç¥¨": pe_sorted.tail(5)[['ts_code', 'pe', 'pb', 'total_mv']].to_dict('records')
                        }
                    }
                    
            # å¸‚å€¼åˆ†æ
            if 'total_mv' in df.columns:
                mv_data = df[df['total_mv'].notna()]
                if len(mv_data) > 0:
                    mv_sorted = mv_data.sort_values('total_mv', ascending=False)
                    if "market_overview" not in result:
                        result["market_overview"] = {"trade_date": trade_date}
                    result["market_overview"]["market_cap_analysis"] = {
                        "æœ€å¤§å¸‚å€¼è‚¡ç¥¨": mv_sorted.head(5)[['ts_code', 'total_mv', 'pe', 'pb']].to_dict('records'),
                        "æœ€å°å¸‚å€¼è‚¡ç¥¨": mv_sorted.tail(5)[['ts_code', 'total_mv', 'pe', 'pb']].to_dict('records')
                    }
        
        print(f"ğŸ“Š æ—¥æŒ‡æ ‡æ•°æ®æ±‡æ€»å®Œæˆ")
        
        import json
        return json.dumps(result, ensure_ascii=False, indent=2)
        
    except Exception as e:
        error_msg = f"è·å–æ—¥æŒ‡æ ‡æ•°æ®å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return f"âŒ é”™è¯¯: {error_msg}"
